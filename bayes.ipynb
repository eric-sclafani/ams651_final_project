{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7bdad1",
   "metadata": {},
   "source": [
    "# Multi-nomial Naive Bayes Classifier\n",
    "\n",
    "## Steps for classification using Naive Bayes:\n",
    "\n",
    "1. `Clean your data` - different ways and options to do this. All I do is remove punctuation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d1902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3732\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from math import log, exp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from text_preprocessor import process_df,tokenizer\n",
    "\n",
    "cleaned_df = process_df(\"ice_cream_reviews.csv\")\n",
    "\n",
    "# 3732 for training (80%), 1600 (20%) for testing, \n",
    "X_train = cleaned_df[1600:]\n",
    "print(len(X_train))\n",
    "\n",
    "X_test = cleaned_df[:1600]\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dca94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    \n",
    "    def __init__(self, train_data, test_data):\n",
    "        \n",
    "        self.train = train_data\n",
    "        self.test = test_data\n",
    "       \n",
    "        # separate positive and negative reviews\n",
    "        self.pos_entries = self.train.loc[self.train[\"sentiment\"]==1]\n",
    "        self.neg_entries = self.train.loc[self.train[\"sentiment\"]==0]\n",
    "    \n",
    "        # all words from each class (need to be lists since I turn them into bag of words)\n",
    "        self.pos_vocab = [word for review in self.pos_entries[\"review\"] for word in review.split()]\n",
    "        self.neg_vocab = [word for review in self.neg_entries[\"review\"] for word in review.split()]\n",
    "        \n",
    "        # bag of words for each class\n",
    "        self.pos_BoW = self._BoW(self.pos_vocab)\n",
    "        self.neg_BoW = self._BoW(self.neg_vocab)\n",
    "    \n",
    "    def _BoW(self, doc):\n",
    "        \n",
    "        d = defaultdict(lambda:0)\n",
    "        for word in doc:\n",
    "            d[word]+=1  \n",
    "        return dict(d)\n",
    "\n",
    "\n",
    "    # class log prior probability\n",
    "    def _Pprob(self, c):\n",
    "        # log of total # of c class reviews divided by total # of reviews\n",
    "        return log(len(c) / (len(self.train)))\n",
    "    \n",
    "    # maxiumum likelihood probability\n",
    "    def _MLprob(self, sentence):\n",
    "        \n",
    "        sentence = tokenizer(sentence)\n",
    "        scores = [] \n",
    "        \n",
    "        # positive and negative log prior probability\n",
    "        pos_prob = self._Pprob(self.pos_entries)\n",
    "        neg_prob = self._Pprob(self.neg_entries)\n",
    "        \n",
    "        \n",
    "        # most important part of the classifier\n",
    "        \n",
    "        # calculates the likelihood probability of each word given the class prior probability\n",
    "        \n",
    "        # laplace (+1) smoothing to prevent possible 0 probabilities\n",
    "        \n",
    "        # reason for try/except: we dont want to deal with words not in training set, so if we try to acces an unattested word, just dont do anything\n",
    "        \n",
    "        # using log speeds up calculations\n",
    "        \n",
    "        # EQUATION: count of word+1 / len(all words in class + len(all reviews)). Need to add len(all reviews) to account for smoothing in numerator.\n",
    "        \n",
    "        for word in sentence: \n",
    "                try:\n",
    "                    w = self.neg_BoW[word] + 1\n",
    "                    #print(\"NEG w:\",w) # testing\n",
    "                    V = (len(self.neg_BoW)+ len(self.train))\n",
    "                    neg_prob += log(w / V)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "        scores.append(exp(neg_prob)) \n",
    "        \n",
    "        for word in sentence: \n",
    "                try:\n",
    "                    w = self.pos_BoW[word]+ 1\n",
    "                    #print(\"POS w:\",w) # testing\n",
    "                    V = (len(self.pos_BoW)+ len(self.train))\n",
    "                    pos_prob += log(w / V)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        scores.append(exp(pos_prob))\n",
    "        \n",
    "        # index 0 == negative, index 1 == positive\n",
    "        return np.argmax(np.array(scores))\n",
    "      \n",
    "    def get_scores(self, extra=False):\n",
    "         \n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        true_neg = 0\n",
    "        false_neg = 0\n",
    "        \n",
    "        test_reviews = self.test[\"review\"]\n",
    "        test_labels = self.test[\"sentiment\"]\n",
    "        \n",
    "        for label, review in zip(test_labels, test_reviews):\n",
    "            \n",
    "            MLprob = self._MLprob(review)\n",
    "\n",
    "            if MLprob == 0 and label == 0:   # predicted neg, label neg \n",
    "                true_neg += 1\n",
    "            elif MLprob == 1 and label == 1: # predicted pos, label pos\n",
    "                true_pos += 1   \n",
    "            elif MLprob == 0 and label == 1: # predicted neg, label pos\n",
    "                false_neg += 1\n",
    "            elif MLprob == 1 and label == 0: # predicted pos, label neg\n",
    "                false_pos += 1 \n",
    "                \n",
    "        # option to print out more details about the results if desired\n",
    "        if extra:\n",
    "            print(\"TN:\",true_neg)\n",
    "            print(\"TP:\",true_pos)\n",
    "            print(\"FP:\",false_pos)\n",
    "            print(\"FN:\",false_neg)\n",
    "        \n",
    "                \n",
    "                \n",
    "        accuracy = (true_neg + true_pos) / (true_pos + true_neg + false_neg + false_pos)\n",
    "        precision = (true_pos) / (true_pos + false_pos)\n",
    "        recall = (true_pos) / (true_pos + false_neg)\n",
    "        f1score = (2* (precision*recall)) / (precision + recall)\n",
    "        \n",
    "        return round(accuracy,3), round(precision,3), round(recall,3), round(f1score, 3)\n",
    "        \n",
    "    def classification_report(self, extra=False):\n",
    "        \n",
    "        accuracy, precision, recall, f1score = self.get_scores(extra)\n",
    "        print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-score: {f1score}\")\n",
    "        \n",
    "        \n",
    "    def confusion_matrix(self):\n",
    "        pass\n",
    "        \n",
    "    def predict(self, review):\n",
    "        pass\n",
    "    \n",
    "    def plotcounts(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# instantiate and fit the model to data\n",
    "model = NaiveBayesClassifier(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e50755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.695\n",
      "Precision: 0.814\n",
      "Recall: 0.797\n",
      "F1-score: 0.805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981cca99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47961957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
